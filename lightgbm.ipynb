{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split  \n",
    "from skopt import BayesSearchCV\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#68941878(2017-11-08 00:00:00) [68941878:131886952]\n",
    "#131886953(2017-11-09 00:00:00)[131886953:]\n",
    "#62945076   2017-11-08 23:59:59\n",
    "#62945077   2017-11-09 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n"
     ]
    }
   ],
   "source": [
    "skip = range(1,131886952)\n",
    "print(\"Loading Data\")\n",
    "train = pd.read_csv('train.csv', skiprows=skip, dtype=dtypes,\n",
    "        header=0,usecols=train_cols,parse_dates=[\"click_time\"])#.sample(1000)\n",
    "test = pd.read_csv('test.csv', dtype=dtypes, header=0,\n",
    "        usecols=test_cols,parse_dates=[\"click_time\"])#.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The initial size of the train set is', 53016939)\n",
      "Binding the training and test set together...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = len(train)\n",
    "print('The initial size of the train set is', len_train)\n",
    "print('Binding the training and test set together...')\n",
    "train=train.append(test)\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features: 'hour' and 'day'...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating new time features: 'hour' and 'day'...\")\n",
    "train['hour'] = train[\"click_time\"].dt.hour.astype('uint8')\n",
    "train['day'] = train[\"click_time\"].dt.day.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features: 'ip_count'...\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new time features: 'ip_count'...\")\n",
    "n_chans = train[['ip','channel']].groupby(by=['ip'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['ip'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features: 'app_count'...\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new time features: 'app_count'...\")\n",
    "n_chans = train[['app','channel']].groupby(by=['app'])[['channel']].count().reset_index().rename(columns={'channel': 'app_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['app'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features: 'user_count'...\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new time features: 'user_count'...\")\n",
    "n_chans = train[['app','ip','device','os','channel']].groupby(by=['app','ip','device','os'])[['channel']].count().reset_index().rename(columns={'channel': 'user_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['app','ip','device','os'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features: 'os_count'...\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new time features: 'os_count'...\")\n",
    "n_chans = train[['ip','device','os','channel']].groupby(by=['ip','device','os'])[['channel']].count().reset_index().rename(columns={'channel': 'os_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['ip','device','os'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features: 'channel_count'...\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new time features: 'channel_count'...\")\n",
    "n_chans = train[['app','channel']].groupby(by=['channel'])[['app']].count().reset_index().rename(columns={'app': 'channel_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['channel'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'n_channels'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'n_channels'\")\n",
    "n_chans = train[['ip','day','hour','channel']].groupby(by=['ip','day',\n",
    "          'hour'])[['channel']].count().reset_index().rename(columns={'channel': 'n_channels'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['ip','day','hour'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_day_ch_hour_var'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_day_ch_hour_var'\")\n",
    "n_chans = train[['ip','day','hour','channel']].groupby(by=['ip','day',\n",
    "          'channel'])[['hour']].var().reset_index().rename(columns={'hour': 'ip_day_ch_hour_var'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['ip','day','channel'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_day_hour_count'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_day_hour_count'\")\n",
    "n_chans = train[['ip','app','day','hour','channel']].groupby(by=['ip','day','hour', \n",
    "          'app'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_app_day_hour_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['ip','day','hour','app'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_count'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_count'\")\n",
    "n_chans = train[['ip','app', 'channel']].groupby(by=['ip', \n",
    "          'app'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_app_count'})\n",
    "print('Merging the channels data with the main data set...')\n",
    "train = train.merge(n_chans, on=['ip','app'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_os_count'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_os_count'\")\n",
    "n_chans = train[['ip','app', 'os', 'channel']].groupby(by=['ip', 'app', \n",
    "          'os'])[['channel']].count().reset_index().rename(columns={'channel': 'ip_app_os_count'})\n",
    "print('Merging the channels data with the main data set...')       \n",
    "train = train.merge(n_chans, on=['ip','app', 'os'], how='left')\n",
    "del n_chans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_day_channel_var'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_day_channel_var'\")\n",
    "gp = train[['ip','day','hour','channel']].groupby(by=['ip',\n",
    "        'day','channel'])[['hour']].var().reset_index().rename(index=str, columns={'hour': 'ip_day_channel_var'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','day','channel'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_os_var'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_os_var'\")\n",
    "gp = train[['ip','app', 'os', 'hour']].groupby(by=['ip', \n",
    "    'app', 'os'])[['hour']].var().reset_index().rename(index=str, columns={'hour': 'ip_app_os_var'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','app', 'os'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_channel_var_day'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_channel_var_day'\")\n",
    "gp = train[['ip','app', 'channel', 'day']].groupby(by=['ip', \n",
    "    'app', 'channel'])[['day']].var().reset_index().rename(index=str, columns={'day': 'ip_app_channel_var_day'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','app','channel'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_channel_count_day'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_channel_count_day'\")\n",
    "gp = train[['ip','app', 'channel', 'day']].groupby(by=['ip', \n",
    "    'app', 'channel'])[['day']].count().reset_index().rename(index=str, columns={'day': 'ip_app_channel_count_day'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','app','channel'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_app_channel_mean_hour'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_app_channel_mean_hour'\")\n",
    "gp = train[['ip','app', 'channel','hour']].groupby(by=['ip', \n",
    "    'app', 'channel'])[['hour']].mean().reset_index().rename(index=str, columns={'hour': 'ip_app_channel_mean_hour'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','app', 'channel'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'ip_dev'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'ip_dev'\")\n",
    "gp = train[['ip', 'device', 'hour', 'channel']].groupby(by=['ip', 'device', \n",
    "            'hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_dev'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','device','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping by ip-day-hour combination...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('grouping by ip-day-hour combination...')\n",
    "gp = train[['ip','day','hour','channel']].groupby(by=['ip','day',\n",
    "                'hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_tcount'})\n",
    "train = train.merge(gp, on=['ip','day','hour'], how='left')\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'in_test_hh'\n",
      "Merging the channels data with the main data set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'in_test_hh'\")\n",
    "most_freq_hours_in_test_data = [4, 5, 9, 10, 13, 14]\n",
    "least_freq_hours_in_test_data = [6, 11, 15]\n",
    "train['in_test_hh'] = (3 - 2*train['hour'].isin(most_freq_hours_in_test_data) - 1*train['hour'].isin( least_freq_hours_in_test_data ) ).astype('uint8')\n",
    "gp = train[['ip', 'day', 'in_test_hh', 'channel']].groupby(by=['ip', 'day', 'in_test_hh'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'nip_day_test_hh'})\n",
    "print('Merging the channels data with the main data set...')   \n",
    "train = train.merge(gp, on=['ip','day','in_test_hh'], how='left')\n",
    "train.drop(['in_test_hh'], axis=1, inplace=True)\n",
    "del gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('selcols', ['ip', 'channel'], 'QQ', 4)\n",
      "('selcols', ['ip', 'device', 'os', 'app'], 'QQ', 5)\n",
      "('selcols', ['ip', 'day', 'hour'], 'QQ', 4)\n",
      "('selcols', ['ip', 'app'], 'QQ', 4)\n",
      "('selcols', ['ip', 'app', 'os'], 'QQ', 4)\n",
      "('selcols', ['ip', 'device'], 'QQ', 4)\n",
      "('selcols', ['app', 'channel'], 'QQ', 4)\n",
      "('selcols', ['ip', 'os'], 'QQ', 5)\n",
      "('selcols', ['ip', 'device', 'os', 'app'], 'QQ', 4)\n"
     ]
    }
   ],
   "source": [
    "naddfeat=9\n",
    "for i in range(0,naddfeat):\n",
    "    if i==0: selcols=['ip', 'channel']; QQ=4;\n",
    "    if i==1: selcols=['ip', 'device', 'os', 'app']; QQ=5;\n",
    "    if i==2: selcols=['ip', 'day', 'hour']; QQ=4;\n",
    "    if i==3: selcols=['ip', 'app']; QQ=4;\n",
    "    if i==4: selcols=['ip', 'app', 'os']; QQ=4;\n",
    "    if i==5: selcols=['ip', 'device']; QQ=4;\n",
    "    if i==6: selcols=['app', 'channel']; QQ=4;\n",
    "    if i==7: selcols=['ip', 'os']; QQ=5;\n",
    "    if i==8: selcols=['ip', 'device', 'os', 'app']; QQ=4;\n",
    "    print('selcols',selcols,'QQ',QQ)\n",
    "        \n",
    "    if QQ==4:\n",
    "        gp = train[selcols].groupby(by=selcols[0:len(selcols)-1])[selcols[len(selcols)-1]].nunique().reset_index().rename(index=str, columns={selcols[len(selcols)-1]: 'X'+str(i)})\n",
    "        train = train.merge(gp, on=selcols[0:len(selcols)-1], how='left')\n",
    "    if QQ==5:\n",
    "        gp = train[selcols].groupby(by=selcols[0:len(selcols)-1])[selcols[len(selcols)-1]].cumcount() + 1\n",
    "        train['X'+str(i)]=gp.values\n",
    "    \n",
    "    del gp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Creating new count features: 'UsrappNewness'\")\n",
    "# train['UsrappNewness'] = train.groupby(['ip','app', 'device', 'os']).cumcount() + 1\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'UsrNewness'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'UsrNewness'\")\n",
    "train['UsrNewness'] = train.groupby(['ip', 'device', 'os']).cumcount() + 1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'time_delta_user'\n",
      "Creating new count features: 'time_delta_user_app'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'time_delta_user'\")\n",
    "train['time_delta_user'] = train.sort_values(['click_time']).groupby(by=['ip','device', 'os'])[['click_time']].diff().astype('timedelta64[s]')\n",
    "gc.collect()\n",
    "\n",
    "# print(\"Creating new count features: 'time_delta_ip'\")\n",
    "# train['time_delta_ip'] = train.sort_values(['click_time']).groupby(by=['ip'])[['click_time']].diff().astype('timedelta64[s]')\n",
    "# gc.collect()\n",
    "\n",
    "print(\"Creating new count features: 'time_delta_user_app'\")\n",
    "train['time_delta_ip_app'] = train.sort_values(['click_time']).groupby(by=['ip','app'])[['click_time']].diff().astype('timedelta64[s]')\n",
    "gc.collect()\n",
    "\n",
    "# print(\"Creating new count features: 'time_delta_ip_cha'\")\n",
    "# train['time_delta_ip_cha'] = train.sort_values(['click_time']).groupby(by=['ip','channel'])[['click_time']].diff().astype('timedelta64[s]')\n",
    "# gc.collect()\n",
    "\n",
    "# print(\"Creating new count features: 'time_delta_ip_dev'\")\n",
    "# train['time_delta_ip_dev'] = train.sort_values(['click_time']).groupby(by=['ip','device'])[['click_time']].diff().astype('timedelta64[s]')\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new count features: 'next_click'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating new count features: 'next_click'\")\n",
    "start = time.time()\n",
    "train['click_time_s'] = (train['click_time'].astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "train['nextClick'] = (train.groupby(['ip', 'app', 'device', 'os']).click_time_s.shift(-1) - train.click_time_s).astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change Here When Change feature\n",
    "predictors = ['ip', 'device', 'app', 'os', 'channel', 'hour', 'n_channels',\n",
    "              'ip_count','ip_app_count', 'ip_app_os_count','day',\n",
    "              'ip_day_channel_var','ip_app_os_var','ip_app_channel_var_day'\n",
    "              ,'ip_app_channel_mean_hour','ip_dev','nip_day_test_hh',\n",
    "              'ip_day_ch_hour_var','ip_app_day_hour_count','UsrNewness'\n",
    "              ,'channel_count','os_count','user_count',\n",
    "              'app_count','ip_app_channel_count_day','ip_tcount','nextClick','time_delta_user'\n",
    "             ,'time_delta_ip_app']#,'time_delta_ip_app','time_delta_ip_cha','time_delta_ip_dev']\n",
    "\n",
    "for i in range(0,naddfeat):\n",
    "        predictors.append('X'+str(i))\n",
    "categorical = ['ip', 'app', 'device', 'os', 'channel', 'hour','day']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_feature = 'nextClick'\n",
    "# D=2**26\n",
    "# train['category'] = (train['ip'].astype(str) + \"_\" + train['app'].astype(str) + \"_\" + train['device'].astype(str) \\\n",
    "#         + \"_\" + train['os'].astype(str)).apply(hash) % D\n",
    "# click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "# train['epochtime']= train['click_time'].astype(np.int64) // 10 ** 9\n",
    "# next_clicks= []\n",
    "# for category, t in zip(reversed(train['category'].values), reversed(train['epochtime'].values)):\n",
    "#     next_clicks.append(click_buffer[category]-t)\n",
    "#     click_buffer[category]= t\n",
    "# del(click_buffer)\n",
    "# QQ= list(reversed(next_clicks))\n",
    "# train.drop(['epochtime','category'], axis=1, inplace=True)\n",
    "# train[new_feature] = pd.Series(QQ).astype('float32')\n",
    "# predictors.append(new_feature)\n",
    "# train[new_feature+'_shift'] = train[new_feature].shift(+1).values\n",
    "# predictors.append(new_feature+'_shift')\n",
    "# del QQ, next_clicks\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predictors:', 38, 'train:', 39)\n"
     ]
    }
   ],
   "source": [
    "print(\"predictors:\", len(predictors), \"train:\", len(train.columns) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the data types of the new count features... \n"
     ]
    }
   ],
   "source": [
    "#Change Here When Change feature\n",
    "print(\"Adjusting the data types of the new count features... \")\n",
    "train['n_channels'] = train['n_channels'].astype('uint16')\n",
    "train['ip_app_count'] = train['ip_app_count'].astype('uint16')\n",
    "train['ip_app_os_count'] = train['ip_app_os_count'].astype('uint16')\n",
    "train['ip_dev'] = train['ip_dev'].astype('uint32')\n",
    "train['nip_day_test_hh'] = train['nip_day_test_hh'].astype('uint32')\n",
    "train['ip_app_day_hour_count'] = train['ip_app_day_hour_count'].astype('uint16')\n",
    "train['app_count'] = train['app_count'].astype('uint16')\n",
    "train['channel_count'] = train['channel_count'].astype('uint16')\n",
    "train['ip_app_channel_count_day'] = train['ip_app_channel_count_day'].astype('uint16')\n",
    "train['ip_count'] = train['ip_count'].astype('uint16')\n",
    "train['user_count'] = train['user_count'].astype('uint16')\n",
    "train['os_count'] = train['os_count'].astype('uint16')\n",
    "train['UsrNewness'] = train['UsrNewness'].astype('uint16')\n",
    "#train['UsrappNewness'] = train['UsrappNewness'].astype('uint16')\n",
    "train['ip_tcount'] = train['ip_tcount'].astype('uint16')\n",
    "\n",
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use Day 8 as train, day 9 as valid\n",
    "# splitTar = 62945077\n",
    "# test = train[len_train:]\n",
    "# train_X = train[:splitTar]\n",
    "# val_X = train[splitTar:]\n",
    "# train_y = train[:splitTar].is_attributed\n",
    "# val_y = train[splitTar:].is_attributed\n",
    "# print('The size of the test set is ', len(test))\n",
    "# print('The size of the validation set is ', len(val_X))\n",
    "# print('The size of the train set is ', len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The size of the test set is ', 18790469)\n",
      "('The size of the validation set is ', 5301694)\n",
      "('The size of the train set is ', 47715245)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random split for both \n",
    "test = train[len_train:]\n",
    "train_ = train[:len_train]\n",
    "target = 'is_attributed'\n",
    "target = train_[target]\n",
    "train_X,val_X, train_y, val_y = train_test_split(train_,target,test_size = 0.1,random_state = 0) \n",
    "train_y = train_y.astype('uint8')\n",
    "val_y = val_y.astype('uint8')\n",
    "print('The size of the test set is ', len(test))\n",
    "print('The size of the validation set is ', len(val_X))\n",
    "print('The size of the train set is ', len(train_X))\n",
    "\n",
    "#del train\n",
    "del train_\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the datasets for training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing the datasets for training...\")\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.25,\n",
    "    'num_leaves': 15,  \n",
    "    'max_depth': 4,  \n",
    "    'min_child_samples': 100,  \n",
    "    'max_bin': 100,  \n",
    "    'subsample': 0.7,  \n",
    "    'subsample_freq': 1,  \n",
    "    'colsample_bytree': 0.7,  \n",
    "    'min_child_weight': 0,  \n",
    "    'subsample_for_bin': 200000,  \n",
    "    'min_split_gain': 0,  \n",
    "    'reg_alpha': 0,  \n",
    "    'reg_lambda': 0,  \n",
    "   # 'nthread': 8,\n",
    "    'verbose': 0,\n",
    "    'scale_pos_weight':100 \n",
    "    }\n",
    "\n",
    "dtrain = lgb.Dataset(train_X[predictors].values, label=train_y.values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "dvalid = lgb.Dataset(val_X[predictors].values, label=val_y.values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "                      \n",
    "evals_results = {}\n",
    "\n",
    "del train_X\n",
    "del val_X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "[1]\ttrain's auc: 0.933033\tvalid's auc: 0.933647\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttrain's auc: 0.96234\tvalid's auc: 0.9629\n",
      "[3]\ttrain's auc: 0.962396\tvalid's auc: 0.962706\n",
      "[4]\ttrain's auc: 0.963959\tvalid's auc: 0.964348\n",
      "[5]\ttrain's auc: 0.966369\tvalid's auc: 0.966587\n",
      "[6]\ttrain's auc: 0.966874\tvalid's auc: 0.967167\n",
      "[7]\ttrain's auc: 0.967167\tvalid's auc: 0.967475\n",
      "[8]\ttrain's auc: 0.971023\tvalid's auc: 0.970686\n",
      "[9]\ttrain's auc: 0.972458\tvalid's auc: 0.972093\n",
      "[10]\ttrain's auc: 0.973787\tvalid's auc: 0.97353\n",
      "[11]\ttrain's auc: 0.974831\tvalid's auc: 0.974256\n",
      "[12]\ttrain's auc: 0.976052\tvalid's auc: 0.975074\n",
      "[13]\ttrain's auc: 0.976839\tvalid's auc: 0.975615\n",
      "[14]\ttrain's auc: 0.978075\tvalid's auc: 0.97657\n",
      "[15]\ttrain's auc: 0.978379\tvalid's auc: 0.976715\n",
      "[16]\ttrain's auc: 0.978761\tvalid's auc: 0.977225\n",
      "[17]\ttrain's auc: 0.978887\tvalid's auc: 0.977199\n",
      "[18]\ttrain's auc: 0.979371\tvalid's auc: 0.977713\n",
      "[19]\ttrain's auc: 0.979947\tvalid's auc: 0.978159\n",
      "[20]\ttrain's auc: 0.980138\tvalid's auc: 0.97837\n",
      "[21]\ttrain's auc: 0.980244\tvalid's auc: 0.978276\n",
      "[22]\ttrain's auc: 0.980738\tvalid's auc: 0.978771\n",
      "[23]\ttrain's auc: 0.9813\tvalid's auc: 0.978893\n",
      "[24]\ttrain's auc: 0.981754\tvalid's auc: 0.978959\n",
      "[25]\ttrain's auc: 0.982201\tvalid's auc: 0.979096\n",
      "[26]\ttrain's auc: 0.98259\tvalid's auc: 0.979142\n",
      "[27]\ttrain's auc: 0.98284\tvalid's auc: 0.97918\n",
      "[28]\ttrain's auc: 0.983308\tvalid's auc: 0.979228\n",
      "[29]\ttrain's auc: 0.983704\tvalid's auc: 0.979338\n",
      "[30]\ttrain's auc: 0.983899\tvalid's auc: 0.979521\n",
      "[31]\ttrain's auc: 0.984054\tvalid's auc: 0.979752\n",
      "[32]\ttrain's auc: 0.984308\tvalid's auc: 0.979734\n",
      "[33]\ttrain's auc: 0.98445\tvalid's auc: 0.97979\n",
      "[34]\ttrain's auc: 0.984575\tvalid's auc: 0.979836\n",
      "[35]\ttrain's auc: 0.98486\tvalid's auc: 0.979836\n",
      "[36]\ttrain's auc: 0.985029\tvalid's auc: 0.980065\n",
      "[37]\ttrain's auc: 0.985121\tvalid's auc: 0.980202\n",
      "[38]\ttrain's auc: 0.985291\tvalid's auc: 0.980186\n",
      "[39]\ttrain's auc: 0.985379\tvalid's auc: 0.980185\n",
      "[40]\ttrain's auc: 0.985533\tvalid's auc: 0.980198\n",
      "[41]\ttrain's auc: 0.985666\tvalid's auc: 0.980256\n",
      "[42]\ttrain's auc: 0.985823\tvalid's auc: 0.98034\n",
      "[43]\ttrain's auc: 0.985872\tvalid's auc: 0.980339\n",
      "[44]\ttrain's auc: 0.985965\tvalid's auc: 0.980408\n",
      "[45]\ttrain's auc: 0.986117\tvalid's auc: 0.980395\n",
      "[46]\ttrain's auc: 0.986176\tvalid's auc: 0.980437\n",
      "[47]\ttrain's auc: 0.986236\tvalid's auc: 0.980412\n",
      "[48]\ttrain's auc: 0.986394\tvalid's auc: 0.980579\n",
      "[49]\ttrain's auc: 0.986473\tvalid's auc: 0.98064\n",
      "[50]\ttrain's auc: 0.986542\tvalid's auc: 0.98076\n",
      "[51]\ttrain's auc: 0.986598\tvalid's auc: 0.980735\n",
      "[52]\ttrain's auc: 0.98671\tvalid's auc: 0.980856\n",
      "[53]\ttrain's auc: 0.986797\tvalid's auc: 0.980955\n",
      "[54]\ttrain's auc: 0.986843\tvalid's auc: 0.980954\n",
      "[55]\ttrain's auc: 0.98689\tvalid's auc: 0.980964\n",
      "[56]\ttrain's auc: 0.986958\tvalid's auc: 0.981071\n",
      "[57]\ttrain's auc: 0.986983\tvalid's auc: 0.981128\n",
      "[58]\ttrain's auc: 0.987029\tvalid's auc: 0.98112\n",
      "[59]\ttrain's auc: 0.987129\tvalid's auc: 0.981166\n",
      "[60]\ttrain's auc: 0.987181\tvalid's auc: 0.981151\n",
      "[61]\ttrain's auc: 0.987222\tvalid's auc: 0.981123\n",
      "[62]\ttrain's auc: 0.987273\tvalid's auc: 0.981105\n",
      "[63]\ttrain's auc: 0.987365\tvalid's auc: 0.98126\n",
      "[64]\ttrain's auc: 0.987408\tvalid's auc: 0.981251\n",
      "[65]\ttrain's auc: 0.987457\tvalid's auc: 0.981243\n",
      "[66]\ttrain's auc: 0.987523\tvalid's auc: 0.981256\n",
      "[67]\ttrain's auc: 0.987633\tvalid's auc: 0.981333\n",
      "[68]\ttrain's auc: 0.987669\tvalid's auc: 0.981299\n",
      "[69]\ttrain's auc: 0.987693\tvalid's auc: 0.981373\n",
      "[70]\ttrain's auc: 0.98773\tvalid's auc: 0.981477\n",
      "[71]\ttrain's auc: 0.987784\tvalid's auc: 0.98153\n",
      "[72]\ttrain's auc: 0.987846\tvalid's auc: 0.981605\n",
      "[73]\ttrain's auc: 0.98792\tvalid's auc: 0.981672\n",
      "[74]\ttrain's auc: 0.987961\tvalid's auc: 0.981644\n",
      "[75]\ttrain's auc: 0.987995\tvalid's auc: 0.981644\n",
      "[76]\ttrain's auc: 0.988028\tvalid's auc: 0.981637\n",
      "[77]\ttrain's auc: 0.988063\tvalid's auc: 0.981633\n",
      "[78]\ttrain's auc: 0.988092\tvalid's auc: 0.981641\n",
      "[79]\ttrain's auc: 0.988117\tvalid's auc: 0.981633\n",
      "[80]\ttrain's auc: 0.988198\tvalid's auc: 0.98173\n",
      "[81]\ttrain's auc: 0.988234\tvalid's auc: 0.981719\n",
      "[82]\ttrain's auc: 0.988274\tvalid's auc: 0.981735\n",
      "[83]\ttrain's auc: 0.988329\tvalid's auc: 0.981811\n",
      "[84]\ttrain's auc: 0.988363\tvalid's auc: 0.981792\n",
      "[85]\ttrain's auc: 0.988381\tvalid's auc: 0.981789\n",
      "[86]\ttrain's auc: 0.988404\tvalid's auc: 0.981789\n",
      "[87]\ttrain's auc: 0.988436\tvalid's auc: 0.981775\n",
      "[88]\ttrain's auc: 0.98846\tvalid's auc: 0.98176\n",
      "[89]\ttrain's auc: 0.988485\tvalid's auc: 0.981764\n",
      "[90]\ttrain's auc: 0.988531\tvalid's auc: 0.981758\n",
      "[91]\ttrain's auc: 0.988593\tvalid's auc: 0.981876\n",
      "[92]\ttrain's auc: 0.988615\tvalid's auc: 0.981871\n",
      "[93]\ttrain's auc: 0.988644\tvalid's auc: 0.981867\n",
      "[94]\ttrain's auc: 0.98867\tvalid's auc: 0.981899\n",
      "[95]\ttrain's auc: 0.988703\tvalid's auc: 0.98188\n",
      "[96]\ttrain's auc: 0.98872\tvalid's auc: 0.981873\n",
      "[97]\ttrain's auc: 0.988728\tvalid's auc: 0.981831\n",
      "[98]\ttrain's auc: 0.988764\tvalid's auc: 0.981864\n",
      "[99]\ttrain's auc: 0.988786\tvalid's auc: 0.981886\n",
      "[100]\ttrain's auc: 0.988802\tvalid's auc: 0.981875\n",
      "[101]\ttrain's auc: 0.98884\tvalid's auc: 0.981866\n",
      "[102]\ttrain's auc: 0.988854\tvalid's auc: 0.981856\n",
      "[103]\ttrain's auc: 0.988867\tvalid's auc: 0.981846\n",
      "[104]\ttrain's auc: 0.988887\tvalid's auc: 0.981863\n",
      "[105]\ttrain's auc: 0.988906\tvalid's auc: 0.981869\n",
      "[106]\ttrain's auc: 0.988935\tvalid's auc: 0.981853\n",
      "[107]\ttrain's auc: 0.988953\tvalid's auc: 0.981838\n",
      "[108]\ttrain's auc: 0.988987\tvalid's auc: 0.981868\n",
      "[109]\ttrain's auc: 0.989004\tvalid's auc: 0.981861\n",
      "[110]\ttrain's auc: 0.989008\tvalid's auc: 0.981858\n",
      "[111]\ttrain's auc: 0.989035\tvalid's auc: 0.981897\n",
      "[112]\ttrain's auc: 0.98905\tvalid's auc: 0.9819\n",
      "[113]\ttrain's auc: 0.98907\tvalid's auc: 0.981904\n",
      "[114]\ttrain's auc: 0.989131\tvalid's auc: 0.981948\n",
      "[115]\ttrain's auc: 0.989148\tvalid's auc: 0.981954\n",
      "[116]\ttrain's auc: 0.989185\tvalid's auc: 0.982051\n",
      "[117]\ttrain's auc: 0.989229\tvalid's auc: 0.982105\n",
      "[118]\ttrain's auc: 0.989242\tvalid's auc: 0.982098\n",
      "[119]\ttrain's auc: 0.989261\tvalid's auc: 0.982088\n",
      "[120]\ttrain's auc: 0.989267\tvalid's auc: 0.98206\n",
      "[121]\ttrain's auc: 0.989286\tvalid's auc: 0.98205\n",
      "[122]\ttrain's auc: 0.989297\tvalid's auc: 0.982051\n",
      "[123]\ttrain's auc: 0.98931\tvalid's auc: 0.982037\n",
      "[124]\ttrain's auc: 0.98932\tvalid's auc: 0.982039\n",
      "[125]\ttrain's auc: 0.989338\tvalid's auc: 0.982045\n",
      "[126]\ttrain's auc: 0.989347\tvalid's auc: 0.982026\n",
      "[127]\ttrain's auc: 0.989354\tvalid's auc: 0.98202\n",
      "[128]\ttrain's auc: 0.98936\tvalid's auc: 0.982011\n",
      "[129]\ttrain's auc: 0.989374\tvalid's auc: 0.981993\n",
      "[130]\ttrain's auc: 0.989379\tvalid's auc: 0.981975\n",
      "[131]\ttrain's auc: 0.989398\tvalid's auc: 0.981954\n",
      "[132]\ttrain's auc: 0.989427\tvalid's auc: 0.982\n",
      "[133]\ttrain's auc: 0.989441\tvalid's auc: 0.981999\n",
      "[134]\ttrain's auc: 0.989453\tvalid's auc: 0.982\n",
      "[135]\ttrain's auc: 0.989466\tvalid's auc: 0.981994\n",
      "[136]\ttrain's auc: 0.989486\tvalid's auc: 0.982018\n",
      "[137]\ttrain's auc: 0.989495\tvalid's auc: 0.982018\n",
      "[138]\ttrain's auc: 0.989526\tvalid's auc: 0.98204\n",
      "[139]\ttrain's auc: 0.989553\tvalid's auc: 0.982041\n",
      "[140]\ttrain's auc: 0.989577\tvalid's auc: 0.982094\n",
      "[141]\ttrain's auc: 0.989594\tvalid's auc: 0.982086\n",
      "[142]\ttrain's auc: 0.989601\tvalid's auc: 0.982077\n",
      "[143]\ttrain's auc: 0.989612\tvalid's auc: 0.982076\n",
      "[144]\ttrain's auc: 0.989627\tvalid's auc: 0.982071\n",
      "[145]\ttrain's auc: 0.989632\tvalid's auc: 0.982059\n",
      "[146]\ttrain's auc: 0.989635\tvalid's auc: 0.982045\n",
      "[147]\ttrain's auc: 0.989652\tvalid's auc: 0.982058\n",
      "[148]\ttrain's auc: 0.989677\tvalid's auc: 0.982081\n",
      "[149]\ttrain's auc: 0.989697\tvalid's auc: 0.982085\n",
      "[150]\ttrain's auc: 0.989706\tvalid's auc: 0.982066\n",
      "[151]\ttrain's auc: 0.989717\tvalid's auc: 0.982062\n",
      "[152]\ttrain's auc: 0.98976\tvalid's auc: 0.982103\n",
      "[153]\ttrain's auc: 0.98977\tvalid's auc: 0.982105\n",
      "[154]\ttrain's auc: 0.989775\tvalid's auc: 0.982104\n",
      "[155]\ttrain's auc: 0.989788\tvalid's auc: 0.982096\n",
      "[156]\ttrain's auc: 0.989809\tvalid's auc: 0.982093\n",
      "[157]\ttrain's auc: 0.989841\tvalid's auc: 0.982133\n",
      "[158]\ttrain's auc: 0.989845\tvalid's auc: 0.982122\n",
      "[159]\ttrain's auc: 0.989852\tvalid's auc: 0.982098\n",
      "[160]\ttrain's auc: 0.989887\tvalid's auc: 0.982117\n",
      "[161]\ttrain's auc: 0.989899\tvalid's auc: 0.982107\n",
      "[162]\ttrain's auc: 0.989905\tvalid's auc: 0.982123\n",
      "[163]\ttrain's auc: 0.989917\tvalid's auc: 0.982129\n",
      "[164]\ttrain's auc: 0.989911\tvalid's auc: 0.982103\n",
      "[165]\ttrain's auc: 0.989927\tvalid's auc: 0.98212\n",
      "[166]\ttrain's auc: 0.989952\tvalid's auc: 0.982144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167]\ttrain's auc: 0.989968\tvalid's auc: 0.982133\n",
      "[168]\ttrain's auc: 0.989967\tvalid's auc: 0.982123\n",
      "[169]\ttrain's auc: 0.989972\tvalid's auc: 0.982103\n",
      "[170]\ttrain's auc: 0.990001\tvalid's auc: 0.982121\n",
      "[171]\ttrain's auc: 0.990014\tvalid's auc: 0.98211\n",
      "[172]\ttrain's auc: 0.990029\tvalid's auc: 0.982098\n",
      "[173]\ttrain's auc: 0.990054\tvalid's auc: 0.982117\n",
      "[174]\ttrain's auc: 0.990059\tvalid's auc: 0.982115\n",
      "[175]\ttrain's auc: 0.990092\tvalid's auc: 0.982123\n",
      "[176]\ttrain's auc: 0.990101\tvalid's auc: 0.982116\n",
      "[177]\ttrain's auc: 0.990111\tvalid's auc: 0.982117\n",
      "[178]\ttrain's auc: 0.990133\tvalid's auc: 0.982157\n",
      "[179]\ttrain's auc: 0.990141\tvalid's auc: 0.98214\n",
      "[180]\ttrain's auc: 0.99015\tvalid's auc: 0.98213\n",
      "[181]\ttrain's auc: 0.990173\tvalid's auc: 0.982179\n",
      "[182]\ttrain's auc: 0.990189\tvalid's auc: 0.982167\n",
      "[183]\ttrain's auc: 0.990197\tvalid's auc: 0.982163\n",
      "[184]\ttrain's auc: 0.9902\tvalid's auc: 0.982168\n",
      "[185]\ttrain's auc: 0.990212\tvalid's auc: 0.982168\n",
      "[186]\ttrain's auc: 0.990221\tvalid's auc: 0.98216\n",
      "[187]\ttrain's auc: 0.990235\tvalid's auc: 0.982145\n",
      "[188]\ttrain's auc: 0.990246\tvalid's auc: 0.982135\n",
      "[189]\ttrain's auc: 0.990283\tvalid's auc: 0.982143\n",
      "[190]\ttrain's auc: 0.99031\tvalid's auc: 0.982151\n",
      "[191]\ttrain's auc: 0.990315\tvalid's auc: 0.982143\n",
      "[192]\ttrain's auc: 0.990332\tvalid's auc: 0.982131\n",
      "[193]\ttrain's auc: 0.990346\tvalid's auc: 0.982156\n",
      "[194]\ttrain's auc: 0.990342\tvalid's auc: 0.982128\n",
      "[195]\ttrain's auc: 0.99035\tvalid's auc: 0.982127\n",
      "[196]\ttrain's auc: 0.990362\tvalid's auc: 0.98211\n",
      "[197]\ttrain's auc: 0.990373\tvalid's auc: 0.982119\n",
      "[198]\ttrain's auc: 0.990381\tvalid's auc: 0.982089\n",
      "[199]\ttrain's auc: 0.990388\tvalid's auc: 0.982073\n",
      "[200]\ttrain's auc: 0.990402\tvalid's auc: 0.982113\n",
      "[201]\ttrain's auc: 0.990416\tvalid's auc: 0.982154\n",
      "[202]\ttrain's auc: 0.990435\tvalid's auc: 0.982158\n",
      "[203]\ttrain's auc: 0.990454\tvalid's auc: 0.982188\n",
      "[204]\ttrain's auc: 0.990469\tvalid's auc: 0.982201\n",
      "[205]\ttrain's auc: 0.990478\tvalid's auc: 0.982201\n",
      "[206]\ttrain's auc: 0.990487\tvalid's auc: 0.982181\n",
      "[207]\ttrain's auc: 0.990501\tvalid's auc: 0.98219\n",
      "[208]\ttrain's auc: 0.99052\tvalid's auc: 0.98221\n",
      "[209]\ttrain's auc: 0.990527\tvalid's auc: 0.982196\n",
      "[210]\ttrain's auc: 0.990531\tvalid's auc: 0.98218\n",
      "[211]\ttrain's auc: 0.990547\tvalid's auc: 0.98219\n",
      "[212]\ttrain's auc: 0.990551\tvalid's auc: 0.982159\n",
      "[213]\ttrain's auc: 0.990575\tvalid's auc: 0.982144\n",
      "[214]\ttrain's auc: 0.990594\tvalid's auc: 0.982165\n",
      "[215]\ttrain's auc: 0.990601\tvalid's auc: 0.982164\n",
      "[216]\ttrain's auc: 0.990611\tvalid's auc: 0.982175\n",
      "[217]\ttrain's auc: 0.990642\tvalid's auc: 0.982212\n",
      "[218]\ttrain's auc: 0.990648\tvalid's auc: 0.982238\n",
      "[219]\ttrain's auc: 0.990651\tvalid's auc: 0.982219\n",
      "[220]\ttrain's auc: 0.990658\tvalid's auc: 0.982211\n",
      "[221]\ttrain's auc: 0.990662\tvalid's auc: 0.982204\n",
      "[222]\ttrain's auc: 0.990668\tvalid's auc: 0.982171\n",
      "[223]\ttrain's auc: 0.990676\tvalid's auc: 0.982157\n",
      "[224]\ttrain's auc: 0.990679\tvalid's auc: 0.982134\n",
      "[225]\ttrain's auc: 0.990693\tvalid's auc: 0.982156\n",
      "[226]\ttrain's auc: 0.990709\tvalid's auc: 0.982146\n",
      "[227]\ttrain's auc: 0.990722\tvalid's auc: 0.982168\n",
      "[228]\ttrain's auc: 0.990722\tvalid's auc: 0.982149\n",
      "[229]\ttrain's auc: 0.990733\tvalid's auc: 0.982137\n",
      "[230]\ttrain's auc: 0.990734\tvalid's auc: 0.982133\n",
      "[231]\ttrain's auc: 0.990737\tvalid's auc: 0.982127\n",
      "[232]\ttrain's auc: 0.99076\tvalid's auc: 0.98211\n",
      "[233]\ttrain's auc: 0.99076\tvalid's auc: 0.982118\n",
      "[234]\ttrain's auc: 0.990781\tvalid's auc: 0.982133\n",
      "[235]\ttrain's auc: 0.990792\tvalid's auc: 0.982148\n",
      "[236]\ttrain's auc: 0.990798\tvalid's auc: 0.982147\n",
      "[237]\ttrain's auc: 0.990804\tvalid's auc: 0.982132\n",
      "[238]\ttrain's auc: 0.99082\tvalid's auc: 0.982153\n",
      "[239]\ttrain's auc: 0.990832\tvalid's auc: 0.982165\n",
      "[240]\ttrain's auc: 0.990835\tvalid's auc: 0.98215\n",
      "[241]\ttrain's auc: 0.990838\tvalid's auc: 0.982145\n",
      "[242]\ttrain's auc: 0.990858\tvalid's auc: 0.982152\n",
      "[243]\ttrain's auc: 0.990878\tvalid's auc: 0.982179\n",
      "[244]\ttrain's auc: 0.990892\tvalid's auc: 0.982165\n",
      "[245]\ttrain's auc: 0.990891\tvalid's auc: 0.982106\n",
      "[246]\ttrain's auc: 0.990903\tvalid's auc: 0.982089\n",
      "[247]\ttrain's auc: 0.990909\tvalid's auc: 0.982065\n",
      "[248]\ttrain's auc: 0.99093\tvalid's auc: 0.982071\n",
      "[249]\ttrain's auc: 0.990935\tvalid's auc: 0.98206\n",
      "[250]\ttrain's auc: 0.990937\tvalid's auc: 0.982044\n",
      "[251]\ttrain's auc: 0.990938\tvalid's auc: 0.982044\n",
      "[252]\ttrain's auc: 0.99095\tvalid's auc: 0.982053\n",
      "[253]\ttrain's auc: 0.990947\tvalid's auc: 0.982034\n",
      "[254]\ttrain's auc: 0.990962\tvalid's auc: 0.982037\n",
      "[255]\ttrain's auc: 0.990974\tvalid's auc: 0.982039\n",
      "[256]\ttrain's auc: 0.990986\tvalid's auc: 0.982081\n",
      "[257]\ttrain's auc: 0.99099\tvalid's auc: 0.982078\n",
      "[258]\ttrain's auc: 0.991006\tvalid's auc: 0.982099\n",
      "[259]\ttrain's auc: 0.991024\tvalid's auc: 0.98211\n",
      "[260]\ttrain's auc: 0.991033\tvalid's auc: 0.9821\n",
      "[261]\ttrain's auc: 0.991036\tvalid's auc: 0.982087\n",
      "[262]\ttrain's auc: 0.99105\tvalid's auc: 0.982096\n",
      "[263]\ttrain's auc: 0.991059\tvalid's auc: 0.982087\n",
      "[264]\ttrain's auc: 0.991059\tvalid's auc: 0.98207\n",
      "[265]\ttrain's auc: 0.99107\tvalid's auc: 0.982076\n",
      "[266]\ttrain's auc: 0.991075\tvalid's auc: 0.982097\n",
      "[267]\ttrain's auc: 0.991078\tvalid's auc: 0.982096\n",
      "[268]\ttrain's auc: 0.99108\tvalid's auc: 0.982075\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttrain's auc: 0.990648\tvalid's auc: 0.982238\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model...\")\n",
    "\n",
    "lgb_model = lgb.train(params, \n",
    "                 dtrain, \n",
    "                 valid_sets=[dtrain, dvalid], \n",
    "                 valid_names=['train','valid'], \n",
    "                 evals_result=evals_results, \n",
    "                 num_boost_round=1500,\n",
    "                 early_stopping_rounds=50,\n",
    "                 verbose_eval=True, \n",
    "                 feval=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\ttrain's auc: 0.990168\tvalid's auc: 0.982148 'learning_rate': 0.2,'num_leaves': 9,'max_depth': 4, \n",
    "#   train's auc: 0.991313\tvalid's auc: 0.983414 'learning_rate': 0.1,'num_leaves': 12,'max_depth': 4,\n",
    "#\ttrain's auc: 0.991293\tvalid's auc: 0.983208 'learning_rate': 0.1,'num_leaves': 15,'max_depth': 5,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"REtraining the model...\")\n",
    "\n",
    "# dtrain = lgb.Dataset(train[predictors].values, \n",
    "#                      label=train.is_attributed.values,\n",
    "#                      feature_name=predictors,\n",
    "#                      categorical_feature=categorical\n",
    "#                     )\n",
    "\n",
    "# lgb_model_re = lgb.train(params, \n",
    "#                          train, \n",
    "#                          num_boost_round=1000, \n",
    "#                          feature_name=predictors, \n",
    "#                          categorical_feature=categorical\n",
    "#                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=[7,10])\n",
    "# lgb.plot_importance(lgb_model, ax=ax,)\n",
    "# plt.title(\"Light GBM Feature Importance\")\n",
    "# plt.savefig('feature_import.png')\n",
    "\n",
    "# # Feature names:\n",
    "# print('Feature names:', lgb_model.feature_name())\n",
    "# # Feature importances:\n",
    "# print('Feature importances:', list(lgb_model.feature_importance()))\n",
    "\n",
    "# feature_imp = pd.DataFrame(lgb_model.feature_name(),list(lgb_model.feature_importance()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for submission...\n",
      "Predicting the submission data...\n",
      "Writing the submission data into a csv file...\n",
      "(18790469, 2)\n",
      "All done...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data for submission...\")\n",
    "\n",
    "submit = pd.read_csv('test.csv', dtype='int', usecols=['click_id'])\n",
    "\n",
    "print(\"Predicting the submission data...\")\n",
    "\n",
    "#submit['is_attributed'] = 0\n",
    "submit['is_attributed'] = lgb_model.predict(test[predictors], num_iteration=lgb_model.best_iteration)\n",
    "#submit['is_attributed'] = lgb_model_re.predict(test[predictors], num_iteration= -1)\n",
    "\n",
    "\n",
    "print(\"Writing the submission data into a csv file...\")\n",
    "print(submit.shape)\n",
    "submit.to_csv('submission_lgb_delta6.csv', index=False)\n",
    "\n",
    "print(\"All done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The size of the test set is ', 18790469)\n",
      "('The size of the validation set is ', 5301694)\n",
      "('The size of the train set is ', 47715245)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random split for both \n",
    "test = train[len_train:]\n",
    "train_ = train[:len_train]\n",
    "target = 'is_attributed'\n",
    "target = train_[target]\n",
    "train_X,val_X, train_y, val_y = train_test_split(train_,target,test_size = 0.1,random_state = 0) \n",
    "train_y = train_y.astype('uint8')\n",
    "val_y = val_y.astype('uint8')\n",
    "print('The size of the test set is ', len(test))\n",
    "print('The size of the validation set is ', len(val_X))\n",
    "print('The size of the train set is ', len(train_X))\n",
    "\n",
    "#del train\n",
    "del train_\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the datasets for training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing the datasets for training...\")\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 15,  \n",
    "    'max_depth': 5,  \n",
    "    'min_child_samples': 100,  \n",
    "    'max_bin': 100,  \n",
    "    'subsample': 0.7,  \n",
    "    'subsample_freq': 1,  \n",
    "    'colsample_bytree': 0.7,  \n",
    "    'min_child_weight': 0,  \n",
    "    'subsample_for_bin': 200000,  \n",
    "    'min_split_gain': 0,  \n",
    "    'reg_alpha': 0,  \n",
    "    'reg_lambda': 0,  \n",
    "   # 'nthread': 8,\n",
    "    'verbose': 0,\n",
    "    'scale_pos_weight':100 \n",
    "    }\n",
    "\n",
    "dtrain = lgb.Dataset(train_X[predictors].values, label=train_y.values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "dvalid = lgb.Dataset(val_X[predictors].values, label=val_y.values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical\n",
    "                      )\n",
    "                      \n",
    "evals_results = {}\n",
    "\n",
    "del train_X\n",
    "del val_X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "[1]\ttrain's auc: 0.938483\tvalid's auc: 0.939107\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttrain's auc: 0.962666\tvalid's auc: 0.963276\n",
      "[3]\ttrain's auc: 0.963631\tvalid's auc: 0.964131\n",
      "[4]\ttrain's auc: 0.964542\tvalid's auc: 0.965074\n",
      "[5]\ttrain's auc: 0.965555\tvalid's auc: 0.966046\n",
      "[6]\ttrain's auc: 0.965891\tvalid's auc: 0.966416\n",
      "[7]\ttrain's auc: 0.965955\tvalid's auc: 0.966451\n",
      "[8]\ttrain's auc: 0.966242\tvalid's auc: 0.966705\n",
      "[9]\ttrain's auc: 0.968148\tvalid's auc: 0.968306\n",
      "[10]\ttrain's auc: 0.968504\tvalid's auc: 0.968606\n",
      "[11]\ttrain's auc: 0.969332\tvalid's auc: 0.969289\n",
      "[12]\ttrain's auc: 0.96992\tvalid's auc: 0.969949\n",
      "[13]\ttrain's auc: 0.970366\tvalid's auc: 0.970359\n",
      "[14]\ttrain's auc: 0.970685\tvalid's auc: 0.970792\n",
      "[15]\ttrain's auc: 0.970481\tvalid's auc: 0.970649\n",
      "[16]\ttrain's auc: 0.970764\tvalid's auc: 0.970989\n",
      "[17]\ttrain's auc: 0.970609\tvalid's auc: 0.970817\n",
      "[18]\ttrain's auc: 0.971712\tvalid's auc: 0.97187\n",
      "[19]\ttrain's auc: 0.972223\tvalid's auc: 0.972182\n",
      "[20]\ttrain's auc: 0.972366\tvalid's auc: 0.972434\n",
      "[21]\ttrain's auc: 0.972396\tvalid's auc: 0.972443\n",
      "[22]\ttrain's auc: 0.972933\tvalid's auc: 0.973041\n",
      "[23]\ttrain's auc: 0.972902\tvalid's auc: 0.972987\n",
      "[24]\ttrain's auc: 0.973059\tvalid's auc: 0.972953\n",
      "[25]\ttrain's auc: 0.974285\tvalid's auc: 0.97388\n",
      "[26]\ttrain's auc: 0.974578\tvalid's auc: 0.973973\n",
      "[27]\ttrain's auc: 0.974617\tvalid's auc: 0.973911\n",
      "[28]\ttrain's auc: 0.975655\tvalid's auc: 0.974578\n",
      "[29]\ttrain's auc: 0.976067\tvalid's auc: 0.97477\n",
      "[30]\ttrain's auc: 0.976439\tvalid's auc: 0.975148\n",
      "[31]\ttrain's auc: 0.976833\tvalid's auc: 0.975593\n",
      "[32]\ttrain's auc: 0.977299\tvalid's auc: 0.975776\n",
      "[33]\ttrain's auc: 0.977724\tvalid's auc: 0.975951\n",
      "[34]\ttrain's auc: 0.978027\tvalid's auc: 0.976054\n",
      "[35]\ttrain's auc: 0.978731\tvalid's auc: 0.976462\n",
      "[36]\ttrain's auc: 0.978915\tvalid's auc: 0.976661\n",
      "[37]\ttrain's auc: 0.979282\tvalid's auc: 0.977018\n",
      "[38]\ttrain's auc: 0.979494\tvalid's auc: 0.977004\n",
      "[39]\ttrain's auc: 0.979936\tvalid's auc: 0.977122\n",
      "[40]\ttrain's auc: 0.980442\tvalid's auc: 0.977342\n",
      "[41]\ttrain's auc: 0.980824\tvalid's auc: 0.977411\n",
      "[42]\ttrain's auc: 0.981033\tvalid's auc: 0.977526\n",
      "[43]\ttrain's auc: 0.981358\tvalid's auc: 0.977603\n",
      "[44]\ttrain's auc: 0.98157\tvalid's auc: 0.977646\n",
      "[45]\ttrain's auc: 0.981809\tvalid's auc: 0.977766\n",
      "[46]\ttrain's auc: 0.981826\tvalid's auc: 0.97784\n",
      "[47]\ttrain's auc: 0.981889\tvalid's auc: 0.977838\n",
      "[48]\ttrain's auc: 0.982243\tvalid's auc: 0.978256\n",
      "[49]\ttrain's auc: 0.9826\tvalid's auc: 0.978363\n",
      "[50]\ttrain's auc: 0.982838\tvalid's auc: 0.978654\n",
      "[51]\ttrain's auc: 0.983076\tvalid's auc: 0.978756\n",
      "[52]\ttrain's auc: 0.983258\tvalid's auc: 0.978958\n",
      "[53]\ttrain's auc: 0.983461\tvalid's auc: 0.97928\n",
      "[54]\ttrain's auc: 0.983685\tvalid's auc: 0.979348\n",
      "[55]\ttrain's auc: 0.983851\tvalid's auc: 0.979355\n",
      "[56]\ttrain's auc: 0.983991\tvalid's auc: 0.979508\n",
      "[57]\ttrain's auc: 0.98414\tvalid's auc: 0.979738\n",
      "[58]\ttrain's auc: 0.98447\tvalid's auc: 0.979819\n",
      "[59]\ttrain's auc: 0.984616\tvalid's auc: 0.979976\n",
      "[60]\ttrain's auc: 0.984793\tvalid's auc: 0.979985\n",
      "[61]\ttrain's auc: 0.985019\tvalid's auc: 0.980051\n",
      "[62]\ttrain's auc: 0.985245\tvalid's auc: 0.980147\n",
      "[63]\ttrain's auc: 0.985348\tvalid's auc: 0.980301\n",
      "[64]\ttrain's auc: 0.985515\tvalid's auc: 0.980318\n",
      "[65]\ttrain's auc: 0.985674\tvalid's auc: 0.980362\n",
      "[66]\ttrain's auc: 0.985838\tvalid's auc: 0.980424\n",
      "[67]\ttrain's auc: 0.985941\tvalid's auc: 0.980512\n",
      "[68]\ttrain's auc: 0.98604\tvalid's auc: 0.980573\n",
      "[69]\ttrain's auc: 0.986101\tvalid's auc: 0.980703\n",
      "[70]\ttrain's auc: 0.986182\tvalid's auc: 0.980801\n",
      "[71]\ttrain's auc: 0.98624\tvalid's auc: 0.980831\n",
      "[72]\ttrain's auc: 0.986273\tvalid's auc: 0.980902\n",
      "[73]\ttrain's auc: 0.986314\tvalid's auc: 0.980952\n",
      "[74]\ttrain's auc: 0.98638\tvalid's auc: 0.980956\n",
      "[75]\ttrain's auc: 0.986454\tvalid's auc: 0.980967\n",
      "[76]\ttrain's auc: 0.986555\tvalid's auc: 0.981014\n",
      "[77]\ttrain's auc: 0.98668\tvalid's auc: 0.981021\n",
      "[78]\ttrain's auc: 0.986724\tvalid's auc: 0.981039\n",
      "[79]\ttrain's auc: 0.986837\tvalid's auc: 0.981039\n",
      "[80]\ttrain's auc: 0.986888\tvalid's auc: 0.98111\n",
      "[81]\ttrain's auc: 0.986957\tvalid's auc: 0.981133\n",
      "[82]\ttrain's auc: 0.987071\tvalid's auc: 0.981157\n",
      "[83]\ttrain's auc: 0.987116\tvalid's auc: 0.981241\n",
      "[84]\ttrain's auc: 0.987139\tvalid's auc: 0.981242\n",
      "[85]\ttrain's auc: 0.987232\tvalid's auc: 0.981296\n",
      "[86]\ttrain's auc: 0.9873\tvalid's auc: 0.981295\n",
      "[87]\ttrain's auc: 0.987348\tvalid's auc: 0.981301\n",
      "[88]\ttrain's auc: 0.987429\tvalid's auc: 0.981328\n",
      "[89]\ttrain's auc: 0.987461\tvalid's auc: 0.981324\n",
      "[90]\ttrain's auc: 0.987539\tvalid's auc: 0.981323\n",
      "[91]\ttrain's auc: 0.987606\tvalid's auc: 0.981407\n",
      "[92]\ttrain's auc: 0.987654\tvalid's auc: 0.981431\n",
      "[93]\ttrain's auc: 0.987674\tvalid's auc: 0.981436\n",
      "[94]\ttrain's auc: 0.987703\tvalid's auc: 0.981497\n",
      "[95]\ttrain's auc: 0.987742\tvalid's auc: 0.981542\n",
      "[96]\ttrain's auc: 0.987769\tvalid's auc: 0.981548\n",
      "[97]\ttrain's auc: 0.987808\tvalid's auc: 0.981545\n",
      "[98]\ttrain's auc: 0.987846\tvalid's auc: 0.98158\n",
      "[99]\ttrain's auc: 0.987914\tvalid's auc: 0.98158\n",
      "[100]\ttrain's auc: 0.988003\tvalid's auc: 0.981599\n",
      "[101]\ttrain's auc: 0.988095\tvalid's auc: 0.981641\n",
      "[102]\ttrain's auc: 0.988127\tvalid's auc: 0.98164\n",
      "[103]\ttrain's auc: 0.988136\tvalid's auc: 0.981643\n",
      "[104]\ttrain's auc: 0.988156\tvalid's auc: 0.981674\n",
      "[105]\ttrain's auc: 0.98817\tvalid's auc: 0.981669\n",
      "[106]\ttrain's auc: 0.988199\tvalid's auc: 0.981675\n",
      "[107]\ttrain's auc: 0.98825\tvalid's auc: 0.981664\n",
      "[108]\ttrain's auc: 0.988281\tvalid's auc: 0.981705\n",
      "[109]\ttrain's auc: 0.988288\tvalid's auc: 0.981709\n",
      "[110]\ttrain's auc: 0.988316\tvalid's auc: 0.981719\n",
      "[111]\ttrain's auc: 0.988358\tvalid's auc: 0.981774\n",
      "[112]\ttrain's auc: 0.988372\tvalid's auc: 0.981781\n",
      "[113]\ttrain's auc: 0.988388\tvalid's auc: 0.981787\n",
      "[114]\ttrain's auc: 0.988442\tvalid's auc: 0.981837\n",
      "[115]\ttrain's auc: 0.988454\tvalid's auc: 0.981845\n",
      "[116]\ttrain's auc: 0.988502\tvalid's auc: 0.981926\n",
      "[117]\ttrain's auc: 0.988536\tvalid's auc: 0.981976\n",
      "[118]\ttrain's auc: 0.988547\tvalid's auc: 0.981974\n",
      "[119]\ttrain's auc: 0.988594\tvalid's auc: 0.981979\n",
      "[120]\ttrain's auc: 0.988604\tvalid's auc: 0.981978\n",
      "[121]\ttrain's auc: 0.988647\tvalid's auc: 0.981983\n",
      "[122]\ttrain's auc: 0.988658\tvalid's auc: 0.981987\n",
      "[123]\ttrain's auc: 0.988702\tvalid's auc: 0.981986\n",
      "[124]\ttrain's auc: 0.988711\tvalid's auc: 0.981981\n",
      "[125]\ttrain's auc: 0.988755\tvalid's auc: 0.981994\n",
      "[126]\ttrain's auc: 0.988765\tvalid's auc: 0.981991\n",
      "[127]\ttrain's auc: 0.9888\tvalid's auc: 0.981997\n",
      "[128]\ttrain's auc: 0.988808\tvalid's auc: 0.981992\n",
      "[129]\ttrain's auc: 0.988833\tvalid's auc: 0.981995\n",
      "[130]\ttrain's auc: 0.988842\tvalid's auc: 0.981995\n",
      "[131]\ttrain's auc: 0.988876\tvalid's auc: 0.982002\n",
      "[132]\ttrain's auc: 0.988906\tvalid's auc: 0.982047\n",
      "[133]\ttrain's auc: 0.988907\tvalid's auc: 0.982042\n",
      "[134]\ttrain's auc: 0.988924\tvalid's auc: 0.982041\n",
      "[135]\ttrain's auc: 0.988937\tvalid's auc: 0.982033\n",
      "[136]\ttrain's auc: 0.988959\tvalid's auc: 0.982066\n",
      "[137]\ttrain's auc: 0.988977\tvalid's auc: 0.982089\n",
      "[138]\ttrain's auc: 0.98901\tvalid's auc: 0.982109\n",
      "[139]\ttrain's auc: 0.989029\tvalid's auc: 0.982135\n",
      "[140]\ttrain's auc: 0.989049\tvalid's auc: 0.982182\n",
      "[141]\ttrain's auc: 0.98906\tvalid's auc: 0.98218\n",
      "[142]\ttrain's auc: 0.989091\tvalid's auc: 0.982194\n",
      "[143]\ttrain's auc: 0.989098\tvalid's auc: 0.982189\n",
      "[144]\ttrain's auc: 0.989104\tvalid's auc: 0.982194\n",
      "[145]\ttrain's auc: 0.989109\tvalid's auc: 0.982188\n",
      "[146]\ttrain's auc: 0.989118\tvalid's auc: 0.982179\n",
      "[147]\ttrain's auc: 0.989136\tvalid's auc: 0.98221\n",
      "[148]\ttrain's auc: 0.98916\tvalid's auc: 0.982226\n",
      "[149]\ttrain's auc: 0.989184\tvalid's auc: 0.98225\n",
      "[150]\ttrain's auc: 0.989189\tvalid's auc: 0.982248\n",
      "[151]\ttrain's auc: 0.989197\tvalid's auc: 0.982236\n",
      "[152]\ttrain's auc: 0.989234\tvalid's auc: 0.98226\n",
      "[153]\ttrain's auc: 0.989242\tvalid's auc: 0.982257\n",
      "[154]\ttrain's auc: 0.989252\tvalid's auc: 0.982251\n",
      "[155]\ttrain's auc: 0.989291\tvalid's auc: 0.982246\n",
      "[156]\ttrain's auc: 0.989298\tvalid's auc: 0.982241\n",
      "[157]\ttrain's auc: 0.989312\tvalid's auc: 0.982275\n",
      "[158]\ttrain's auc: 0.989319\tvalid's auc: 0.982275\n",
      "[159]\ttrain's auc: 0.989327\tvalid's auc: 0.982272\n",
      "[160]\ttrain's auc: 0.989346\tvalid's auc: 0.982301\n",
      "[161]\ttrain's auc: 0.989351\tvalid's auc: 0.9823\n",
      "[162]\ttrain's auc: 0.989358\tvalid's auc: 0.982292\n",
      "[163]\ttrain's auc: 0.989364\tvalid's auc: 0.982291\n",
      "[164]\ttrain's auc: 0.98937\tvalid's auc: 0.982288\n",
      "[165]\ttrain's auc: 0.989379\tvalid's auc: 0.982281\n",
      "[166]\ttrain's auc: 0.989405\tvalid's auc: 0.982302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167]\ttrain's auc: 0.989411\tvalid's auc: 0.982301\n",
      "[168]\ttrain's auc: 0.98942\tvalid's auc: 0.982295\n",
      "[169]\ttrain's auc: 0.98943\tvalid's auc: 0.982294\n",
      "[170]\ttrain's auc: 0.989455\tvalid's auc: 0.982315\n",
      "[171]\ttrain's auc: 0.989462\tvalid's auc: 0.982311\n",
      "[172]\ttrain's auc: 0.989471\tvalid's auc: 0.982312\n",
      "[173]\ttrain's auc: 0.989495\tvalid's auc: 0.982354\n",
      "[174]\ttrain's auc: 0.989502\tvalid's auc: 0.982351\n",
      "[175]\ttrain's auc: 0.98953\tvalid's auc: 0.982372\n",
      "[176]\ttrain's auc: 0.989537\tvalid's auc: 0.982373\n",
      "[177]\ttrain's auc: 0.989545\tvalid's auc: 0.982374\n",
      "[178]\ttrain's auc: 0.989568\tvalid's auc: 0.982413\n",
      "[179]\ttrain's auc: 0.989573\tvalid's auc: 0.982409\n",
      "[180]\ttrain's auc: 0.989589\tvalid's auc: 0.982404\n",
      "[181]\ttrain's auc: 0.989611\tvalid's auc: 0.982446\n",
      "[182]\ttrain's auc: 0.989618\tvalid's auc: 0.982442\n",
      "[183]\ttrain's auc: 0.989626\tvalid's auc: 0.982448\n",
      "[184]\ttrain's auc: 0.989634\tvalid's auc: 0.982447\n",
      "[185]\ttrain's auc: 0.989644\tvalid's auc: 0.982444\n",
      "[186]\ttrain's auc: 0.989648\tvalid's auc: 0.982447\n",
      "[187]\ttrain's auc: 0.989653\tvalid's auc: 0.98244\n",
      "[188]\ttrain's auc: 0.989668\tvalid's auc: 0.982442\n",
      "[189]\ttrain's auc: 0.989691\tvalid's auc: 0.982465\n",
      "[190]\ttrain's auc: 0.989709\tvalid's auc: 0.98248\n",
      "[191]\ttrain's auc: 0.989716\tvalid's auc: 0.982475\n",
      "[192]\ttrain's auc: 0.989725\tvalid's auc: 0.982471\n",
      "[193]\ttrain's auc: 0.989734\tvalid's auc: 0.982488\n",
      "[194]\ttrain's auc: 0.98974\tvalid's auc: 0.982483\n",
      "[195]\ttrain's auc: 0.989743\tvalid's auc: 0.982479\n",
      "[196]\ttrain's auc: 0.989754\tvalid's auc: 0.98247\n",
      "[197]\ttrain's auc: 0.989774\tvalid's auc: 0.98248\n",
      "[198]\ttrain's auc: 0.989778\tvalid's auc: 0.982475\n",
      "[199]\ttrain's auc: 0.989783\tvalid's auc: 0.982468\n",
      "[200]\ttrain's auc: 0.989792\tvalid's auc: 0.982481\n",
      "[201]\ttrain's auc: 0.98981\tvalid's auc: 0.982522\n",
      "[202]\ttrain's auc: 0.989819\tvalid's auc: 0.982549\n",
      "[203]\ttrain's auc: 0.989843\tvalid's auc: 0.982581\n",
      "[204]\ttrain's auc: 0.989859\tvalid's auc: 0.982602\n",
      "[205]\ttrain's auc: 0.989865\tvalid's auc: 0.982596\n",
      "[206]\ttrain's auc: 0.989871\tvalid's auc: 0.982593\n",
      "[207]\ttrain's auc: 0.989895\tvalid's auc: 0.982622\n",
      "[208]\ttrain's auc: 0.989916\tvalid's auc: 0.982649\n",
      "[209]\ttrain's auc: 0.989919\tvalid's auc: 0.982646\n",
      "[210]\ttrain's auc: 0.989923\tvalid's auc: 0.98265\n",
      "[211]\ttrain's auc: 0.989926\tvalid's auc: 0.982649\n",
      "[212]\ttrain's auc: 0.989931\tvalid's auc: 0.982644\n",
      "[213]\ttrain's auc: 0.989936\tvalid's auc: 0.982647\n",
      "[214]\ttrain's auc: 0.989969\tvalid's auc: 0.982675\n",
      "[215]\ttrain's auc: 0.989973\tvalid's auc: 0.982674\n",
      "[216]\ttrain's auc: 0.989982\tvalid's auc: 0.982696\n",
      "[217]\ttrain's auc: 0.990017\tvalid's auc: 0.982732\n",
      "[218]\ttrain's auc: 0.990028\tvalid's auc: 0.982751\n",
      "[219]\ttrain's auc: 0.990032\tvalid's auc: 0.982751\n",
      "[220]\ttrain's auc: 0.990039\tvalid's auc: 0.982748\n",
      "[221]\ttrain's auc: 0.990044\tvalid's auc: 0.982751\n",
      "[222]\ttrain's auc: 0.990049\tvalid's auc: 0.982743\n",
      "[223]\ttrain's auc: 0.990055\tvalid's auc: 0.982741\n",
      "[224]\ttrain's auc: 0.990063\tvalid's auc: 0.982735\n",
      "[225]\ttrain's auc: 0.990077\tvalid's auc: 0.982756\n",
      "[226]\ttrain's auc: 0.990084\tvalid's auc: 0.982759\n",
      "[227]\ttrain's auc: 0.990102\tvalid's auc: 0.982777\n",
      "[228]\ttrain's auc: 0.990108\tvalid's auc: 0.982773\n",
      "[229]\ttrain's auc: 0.990112\tvalid's auc: 0.982769\n",
      "[230]\ttrain's auc: 0.990118\tvalid's auc: 0.982759\n",
      "[231]\ttrain's auc: 0.990126\tvalid's auc: 0.982761\n",
      "[232]\ttrain's auc: 0.990131\tvalid's auc: 0.982755\n",
      "[233]\ttrain's auc: 0.990135\tvalid's auc: 0.982751\n",
      "[234]\ttrain's auc: 0.990152\tvalid's auc: 0.982764\n",
      "[235]\ttrain's auc: 0.990171\tvalid's auc: 0.982776\n",
      "[236]\ttrain's auc: 0.990178\tvalid's auc: 0.982771\n",
      "[237]\ttrain's auc: 0.990183\tvalid's auc: 0.982765\n",
      "[238]\ttrain's auc: 0.990205\tvalid's auc: 0.982778\n",
      "[239]\ttrain's auc: 0.990208\tvalid's auc: 0.982778\n",
      "[240]\ttrain's auc: 0.990215\tvalid's auc: 0.982778\n",
      "[241]\ttrain's auc: 0.990219\tvalid's auc: 0.982778\n",
      "[242]\ttrain's auc: 0.99023\tvalid's auc: 0.982787\n",
      "[243]\ttrain's auc: 0.990244\tvalid's auc: 0.982805\n",
      "[244]\ttrain's auc: 0.990255\tvalid's auc: 0.982806\n",
      "[245]\ttrain's auc: 0.99026\tvalid's auc: 0.982797\n",
      "[246]\ttrain's auc: 0.990262\tvalid's auc: 0.982798\n",
      "[247]\ttrain's auc: 0.99027\tvalid's auc: 0.982797\n",
      "[248]\ttrain's auc: 0.990288\tvalid's auc: 0.982819\n",
      "[249]\ttrain's auc: 0.990297\tvalid's auc: 0.982818\n",
      "[250]\ttrain's auc: 0.990301\tvalid's auc: 0.982819\n",
      "[251]\ttrain's auc: 0.990308\tvalid's auc: 0.982822\n",
      "[252]\ttrain's auc: 0.990321\tvalid's auc: 0.982835\n",
      "[253]\ttrain's auc: 0.990325\tvalid's auc: 0.982833\n",
      "[254]\ttrain's auc: 0.990335\tvalid's auc: 0.982845\n",
      "[255]\ttrain's auc: 0.990343\tvalid's auc: 0.982841\n",
      "[256]\ttrain's auc: 0.990352\tvalid's auc: 0.982876\n",
      "[257]\ttrain's auc: 0.990361\tvalid's auc: 0.982877\n",
      "[258]\ttrain's auc: 0.990376\tvalid's auc: 0.982907\n",
      "[259]\ttrain's auc: 0.99039\tvalid's auc: 0.982909\n",
      "[260]\ttrain's auc: 0.990396\tvalid's auc: 0.982907\n",
      "[261]\ttrain's auc: 0.990398\tvalid's auc: 0.982909\n",
      "[262]\ttrain's auc: 0.990405\tvalid's auc: 0.982918\n",
      "[263]\ttrain's auc: 0.990408\tvalid's auc: 0.982915\n",
      "[264]\ttrain's auc: 0.990414\tvalid's auc: 0.982918\n",
      "[265]\ttrain's auc: 0.99043\tvalid's auc: 0.982933\n",
      "[266]\ttrain's auc: 0.990435\tvalid's auc: 0.982937\n",
      "[267]\ttrain's auc: 0.99044\tvalid's auc: 0.982937\n",
      "[268]\ttrain's auc: 0.990444\tvalid's auc: 0.982925\n",
      "[269]\ttrain's auc: 0.990457\tvalid's auc: 0.982944\n",
      "[270]\ttrain's auc: 0.990469\tvalid's auc: 0.982962\n",
      "[271]\ttrain's auc: 0.990489\tvalid's auc: 0.982983\n",
      "[272]\ttrain's auc: 0.990494\tvalid's auc: 0.982968\n",
      "[273]\ttrain's auc: 0.990496\tvalid's auc: 0.982976\n",
      "[274]\ttrain's auc: 0.990514\tvalid's auc: 0.983001\n",
      "[275]\ttrain's auc: 0.990516\tvalid's auc: 0.983009\n",
      "[276]\ttrain's auc: 0.990526\tvalid's auc: 0.983012\n",
      "[277]\ttrain's auc: 0.990529\tvalid's auc: 0.98301\n",
      "[278]\ttrain's auc: 0.990534\tvalid's auc: 0.983005\n",
      "[279]\ttrain's auc: 0.990539\tvalid's auc: 0.983017\n",
      "[280]\ttrain's auc: 0.990542\tvalid's auc: 0.983015\n",
      "[281]\ttrain's auc: 0.990545\tvalid's auc: 0.98301\n",
      "[282]\ttrain's auc: 0.99055\tvalid's auc: 0.983004\n",
      "[283]\ttrain's auc: 0.990554\tvalid's auc: 0.983005\n",
      "[284]\ttrain's auc: 0.990566\tvalid's auc: 0.98303\n",
      "[285]\ttrain's auc: 0.990569\tvalid's auc: 0.983033\n",
      "[286]\ttrain's auc: 0.990588\tvalid's auc: 0.983053\n",
      "[287]\ttrain's auc: 0.990599\tvalid's auc: 0.983059\n",
      "[288]\ttrain's auc: 0.990601\tvalid's auc: 0.983065\n",
      "[289]\ttrain's auc: 0.990612\tvalid's auc: 0.983078\n",
      "[290]\ttrain's auc: 0.990626\tvalid's auc: 0.983096\n",
      "[291]\ttrain's auc: 0.990641\tvalid's auc: 0.983116\n",
      "[292]\ttrain's auc: 0.990647\tvalid's auc: 0.983117\n",
      "[293]\ttrain's auc: 0.990652\tvalid's auc: 0.983115\n",
      "[294]\ttrain's auc: 0.990659\tvalid's auc: 0.983116\n",
      "[295]\ttrain's auc: 0.990676\tvalid's auc: 0.983113\n",
      "[296]\ttrain's auc: 0.990682\tvalid's auc: 0.983108\n",
      "[297]\ttrain's auc: 0.990691\tvalid's auc: 0.98312\n",
      "[298]\ttrain's auc: 0.990704\tvalid's auc: 0.983139\n",
      "[299]\ttrain's auc: 0.990713\tvalid's auc: 0.983143\n",
      "[300]\ttrain's auc: 0.990721\tvalid's auc: 0.983153\n",
      "[301]\ttrain's auc: 0.990724\tvalid's auc: 0.983146\n",
      "[302]\ttrain's auc: 0.990728\tvalid's auc: 0.983143\n",
      "[303]\ttrain's auc: 0.990731\tvalid's auc: 0.98314\n",
      "[304]\ttrain's auc: 0.990738\tvalid's auc: 0.983128\n",
      "[305]\ttrain's auc: 0.990747\tvalid's auc: 0.983142\n",
      "[306]\ttrain's auc: 0.990749\tvalid's auc: 0.983138\n",
      "[307]\ttrain's auc: 0.990757\tvalid's auc: 0.983145\n",
      "[308]\ttrain's auc: 0.990761\tvalid's auc: 0.983144\n",
      "[309]\ttrain's auc: 0.990767\tvalid's auc: 0.983136\n",
      "[310]\ttrain's auc: 0.99078\tvalid's auc: 0.983146\n",
      "[311]\ttrain's auc: 0.990792\tvalid's auc: 0.98315\n",
      "[312]\ttrain's auc: 0.990795\tvalid's auc: 0.983138\n",
      "[313]\ttrain's auc: 0.990799\tvalid's auc: 0.983129\n",
      "[314]\ttrain's auc: 0.990808\tvalid's auc: 0.983127\n",
      "[315]\ttrain's auc: 0.990811\tvalid's auc: 0.983134\n",
      "[316]\ttrain's auc: 0.990816\tvalid's auc: 0.983141\n",
      "[317]\ttrain's auc: 0.990822\tvalid's auc: 0.983136\n",
      "[318]\ttrain's auc: 0.990829\tvalid's auc: 0.983136\n",
      "[319]\ttrain's auc: 0.990833\tvalid's auc: 0.983135\n",
      "[320]\ttrain's auc: 0.990834\tvalid's auc: 0.98313\n",
      "[321]\ttrain's auc: 0.990839\tvalid's auc: 0.98313\n",
      "[322]\ttrain's auc: 0.990843\tvalid's auc: 0.983136\n",
      "[323]\ttrain's auc: 0.990853\tvalid's auc: 0.983151\n",
      "[324]\ttrain's auc: 0.990857\tvalid's auc: 0.983149\n",
      "[325]\ttrain's auc: 0.99086\tvalid's auc: 0.983147\n",
      "[326]\ttrain's auc: 0.990862\tvalid's auc: 0.983149\n",
      "[327]\ttrain's auc: 0.990864\tvalid's auc: 0.983153\n",
      "[328]\ttrain's auc: 0.990882\tvalid's auc: 0.983169\n",
      "[329]\ttrain's auc: 0.990894\tvalid's auc: 0.983174\n",
      "[330]\ttrain's auc: 0.990897\tvalid's auc: 0.983165\n",
      "[331]\ttrain's auc: 0.9909\tvalid's auc: 0.983159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332]\ttrain's auc: 0.990904\tvalid's auc: 0.983159\n",
      "[333]\ttrain's auc: 0.990911\tvalid's auc: 0.983166\n",
      "[334]\ttrain's auc: 0.990917\tvalid's auc: 0.983169\n",
      "[335]\ttrain's auc: 0.990919\tvalid's auc: 0.983167\n",
      "[336]\ttrain's auc: 0.990922\tvalid's auc: 0.983162\n",
      "[337]\ttrain's auc: 0.990925\tvalid's auc: 0.983167\n",
      "[338]\ttrain's auc: 0.99093\tvalid's auc: 0.983161\n",
      "[339]\ttrain's auc: 0.990932\tvalid's auc: 0.983161\n",
      "[340]\ttrain's auc: 0.990936\tvalid's auc: 0.983157\n",
      "[341]\ttrain's auc: 0.990944\tvalid's auc: 0.983155\n",
      "[342]\ttrain's auc: 0.990951\tvalid's auc: 0.983158\n",
      "[343]\ttrain's auc: 0.990954\tvalid's auc: 0.983153\n",
      "[344]\ttrain's auc: 0.990956\tvalid's auc: 0.98315\n",
      "[345]\ttrain's auc: 0.990959\tvalid's auc: 0.983149\n",
      "[346]\ttrain's auc: 0.990961\tvalid's auc: 0.983147\n",
      "[347]\ttrain's auc: 0.990973\tvalid's auc: 0.983157\n",
      "[348]\ttrain's auc: 0.990976\tvalid's auc: 0.983152\n",
      "[349]\ttrain's auc: 0.990993\tvalid's auc: 0.983159\n",
      "[350]\ttrain's auc: 0.990996\tvalid's auc: 0.983159\n",
      "[351]\ttrain's auc: 0.990997\tvalid's auc: 0.983155\n",
      "[352]\ttrain's auc: 0.991015\tvalid's auc: 0.983161\n",
      "[353]\ttrain's auc: 0.99102\tvalid's auc: 0.983167\n",
      "[354]\ttrain's auc: 0.991031\tvalid's auc: 0.983166\n",
      "[355]\ttrain's auc: 0.991036\tvalid's auc: 0.983175\n",
      "[356]\ttrain's auc: 0.991044\tvalid's auc: 0.983186\n",
      "[357]\ttrain's auc: 0.991049\tvalid's auc: 0.98319\n",
      "[358]\ttrain's auc: 0.991055\tvalid's auc: 0.983197\n",
      "[359]\ttrain's auc: 0.991058\tvalid's auc: 0.983191\n",
      "[360]\ttrain's auc: 0.991063\tvalid's auc: 0.983188\n",
      "[361]\ttrain's auc: 0.991065\tvalid's auc: 0.98318\n",
      "[362]\ttrain's auc: 0.991067\tvalid's auc: 0.983176\n",
      "[363]\ttrain's auc: 0.991072\tvalid's auc: 0.983179\n",
      "[364]\ttrain's auc: 0.991076\tvalid's auc: 0.983169\n",
      "[365]\ttrain's auc: 0.99108\tvalid's auc: 0.983168\n",
      "[366]\ttrain's auc: 0.991081\tvalid's auc: 0.983166\n",
      "[367]\ttrain's auc: 0.991086\tvalid's auc: 0.983158\n",
      "[368]\ttrain's auc: 0.99109\tvalid's auc: 0.98316\n",
      "[369]\ttrain's auc: 0.991094\tvalid's auc: 0.983162\n",
      "[370]\ttrain's auc: 0.991097\tvalid's auc: 0.983159\n",
      "[371]\ttrain's auc: 0.991101\tvalid's auc: 0.983161\n",
      "[372]\ttrain's auc: 0.991109\tvalid's auc: 0.98317\n",
      "[373]\ttrain's auc: 0.991111\tvalid's auc: 0.983168\n",
      "[374]\ttrain's auc: 0.991113\tvalid's auc: 0.983158\n",
      "[375]\ttrain's auc: 0.991119\tvalid's auc: 0.983168\n",
      "[376]\ttrain's auc: 0.991129\tvalid's auc: 0.983174\n",
      "[377]\ttrain's auc: 0.991132\tvalid's auc: 0.983173\n",
      "[378]\ttrain's auc: 0.991136\tvalid's auc: 0.983171\n",
      "[379]\ttrain's auc: 0.991141\tvalid's auc: 0.983171\n",
      "[380]\ttrain's auc: 0.99115\tvalid's auc: 0.983175\n",
      "[381]\ttrain's auc: 0.991154\tvalid's auc: 0.983174\n",
      "[382]\ttrain's auc: 0.991158\tvalid's auc: 0.983173\n",
      "[383]\ttrain's auc: 0.99116\tvalid's auc: 0.98317\n",
      "[384]\ttrain's auc: 0.991173\tvalid's auc: 0.983179\n",
      "[385]\ttrain's auc: 0.991175\tvalid's auc: 0.98318\n",
      "[386]\ttrain's auc: 0.991178\tvalid's auc: 0.983174\n",
      "[387]\ttrain's auc: 0.991184\tvalid's auc: 0.983178\n",
      "[388]\ttrain's auc: 0.991189\tvalid's auc: 0.983182\n",
      "[389]\ttrain's auc: 0.991192\tvalid's auc: 0.983177\n",
      "[390]\ttrain's auc: 0.991202\tvalid's auc: 0.983179\n",
      "[391]\ttrain's auc: 0.991209\tvalid's auc: 0.983201\n",
      "[392]\ttrain's auc: 0.991211\tvalid's auc: 0.983191\n",
      "[393]\ttrain's auc: 0.991215\tvalid's auc: 0.983183\n",
      "[394]\ttrain's auc: 0.991219\tvalid's auc: 0.983172\n",
      "[395]\ttrain's auc: 0.991226\tvalid's auc: 0.983171\n",
      "[396]\ttrain's auc: 0.991231\tvalid's auc: 0.983178\n",
      "[397]\ttrain's auc: 0.991233\tvalid's auc: 0.983177\n",
      "[398]\ttrain's auc: 0.991241\tvalid's auc: 0.983191\n",
      "[399]\ttrain's auc: 0.991243\tvalid's auc: 0.983194\n",
      "[400]\ttrain's auc: 0.991247\tvalid's auc: 0.9832\n",
      "[401]\ttrain's auc: 0.991249\tvalid's auc: 0.983191\n",
      "[402]\ttrain's auc: 0.991264\tvalid's auc: 0.983203\n",
      "[403]\ttrain's auc: 0.991268\tvalid's auc: 0.983204\n",
      "[404]\ttrain's auc: 0.991272\tvalid's auc: 0.983202\n",
      "[405]\ttrain's auc: 0.991285\tvalid's auc: 0.983206\n",
      "[406]\ttrain's auc: 0.99129\tvalid's auc: 0.983207\n",
      "[407]\ttrain's auc: 0.991293\tvalid's auc: 0.983208\n",
      "[408]\ttrain's auc: 0.991294\tvalid's auc: 0.983199\n",
      "[409]\ttrain's auc: 0.991298\tvalid's auc: 0.9832\n",
      "[410]\ttrain's auc: 0.991301\tvalid's auc: 0.983205\n",
      "[411]\ttrain's auc: 0.991308\tvalid's auc: 0.983202\n",
      "[412]\ttrain's auc: 0.991317\tvalid's auc: 0.983203\n",
      "[413]\ttrain's auc: 0.991321\tvalid's auc: 0.983199\n",
      "[414]\ttrain's auc: 0.991325\tvalid's auc: 0.983201\n",
      "[415]\ttrain's auc: 0.991328\tvalid's auc: 0.983194\n",
      "[416]\ttrain's auc: 0.991331\tvalid's auc: 0.983195\n",
      "[417]\ttrain's auc: 0.991332\tvalid's auc: 0.983194\n",
      "[418]\ttrain's auc: 0.991338\tvalid's auc: 0.983196\n",
      "[419]\ttrain's auc: 0.991346\tvalid's auc: 0.983185\n",
      "[420]\ttrain's auc: 0.991348\tvalid's auc: 0.983175\n",
      "[421]\ttrain's auc: 0.991358\tvalid's auc: 0.983176\n",
      "[422]\ttrain's auc: 0.991362\tvalid's auc: 0.983186\n",
      "[423]\ttrain's auc: 0.99137\tvalid's auc: 0.98319\n",
      "[424]\ttrain's auc: 0.991376\tvalid's auc: 0.983181\n",
      "[425]\ttrain's auc: 0.991379\tvalid's auc: 0.983177\n",
      "[426]\ttrain's auc: 0.991385\tvalid's auc: 0.983166\n",
      "[427]\ttrain's auc: 0.991386\tvalid's auc: 0.983165\n",
      "[428]\ttrain's auc: 0.991389\tvalid's auc: 0.983156\n",
      "[429]\ttrain's auc: 0.991392\tvalid's auc: 0.983162\n",
      "[430]\ttrain's auc: 0.991396\tvalid's auc: 0.983159\n",
      "[431]\ttrain's auc: 0.991405\tvalid's auc: 0.983167\n",
      "[432]\ttrain's auc: 0.991406\tvalid's auc: 0.983165\n",
      "[433]\ttrain's auc: 0.99141\tvalid's auc: 0.983157\n",
      "[434]\ttrain's auc: 0.991416\tvalid's auc: 0.983157\n",
      "[435]\ttrain's auc: 0.991423\tvalid's auc: 0.983166\n",
      "[436]\ttrain's auc: 0.991427\tvalid's auc: 0.983176\n",
      "[437]\ttrain's auc: 0.991433\tvalid's auc: 0.983175\n",
      "[438]\ttrain's auc: 0.991435\tvalid's auc: 0.983173\n",
      "[439]\ttrain's auc: 0.991438\tvalid's auc: 0.983163\n",
      "[440]\ttrain's auc: 0.99144\tvalid's auc: 0.983162\n",
      "[441]\ttrain's auc: 0.991446\tvalid's auc: 0.983158\n",
      "[442]\ttrain's auc: 0.991448\tvalid's auc: 0.983149\n",
      "[443]\ttrain's auc: 0.991451\tvalid's auc: 0.983153\n",
      "[444]\ttrain's auc: 0.991457\tvalid's auc: 0.983158\n",
      "[445]\ttrain's auc: 0.99146\tvalid's auc: 0.983153\n",
      "[446]\ttrain's auc: 0.991466\tvalid's auc: 0.983149\n",
      "[447]\ttrain's auc: 0.991474\tvalid's auc: 0.983158\n",
      "[448]\ttrain's auc: 0.991477\tvalid's auc: 0.983155\n",
      "[449]\ttrain's auc: 0.991486\tvalid's auc: 0.983161\n",
      "[450]\ttrain's auc: 0.991489\tvalid's auc: 0.98315\n",
      "[451]\ttrain's auc: 0.991492\tvalid's auc: 0.98315\n",
      "[452]\ttrain's auc: 0.991505\tvalid's auc: 0.98316\n",
      "[453]\ttrain's auc: 0.991514\tvalid's auc: 0.983168\n",
      "[454]\ttrain's auc: 0.991517\tvalid's auc: 0.983162\n",
      "[455]\ttrain's auc: 0.991521\tvalid's auc: 0.983159\n",
      "[456]\ttrain's auc: 0.991527\tvalid's auc: 0.983168\n",
      "[457]\ttrain's auc: 0.991531\tvalid's auc: 0.983165\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttrain's auc: 0.991293\tvalid's auc: 0.983208\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model...\")\n",
    "\n",
    "lgb_model = lgb.train(params, \n",
    "                 dtrain, \n",
    "                 valid_sets=[dtrain, dvalid], \n",
    "                 valid_names=['train','valid'], \n",
    "                 evals_result=evals_results, \n",
    "                 num_boost_round=1500,\n",
    "                 early_stopping_rounds=50,\n",
    "                 verbose_eval=True, \n",
    "                 feval=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for submission...\n",
      "Predicting the submission data...\n",
      "Writing the submission data into a csv file...\n",
      "(18790469, 2)\n",
      "All done...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data for submission...\")\n",
    "\n",
    "submit = pd.read_csv('test.csv', dtype='int', usecols=['click_id'])\n",
    "\n",
    "print(\"Predicting the submission data...\")\n",
    "\n",
    "#submit['is_attributed'] = 0\n",
    "submit['is_attributed'] = lgb_model.predict(test[predictors], num_iteration=lgb_model.best_iteration)\n",
    "#submit['is_attributed'] = lgb_model_re.predict(test[predictors], num_iteration= -1)\n",
    "\n",
    "\n",
    "print(\"Writing the submission data into a csv file...\")\n",
    "print(submit.shape)\n",
    "submit.to_csv('submission_lgb_delta7.csv', index=False)\n",
    "\n",
    "print(\"All done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train[len_train:]\n",
    "train_ = train[:len_train]\n",
    "target = 'is_attributed'\n",
    "target = train_[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "ITERATIONS = 1000\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = lgb.LGBMRegressor(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        n_jobs=1,\n",
    "        verbose=0\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'num_leaves': (1, 100),      \n",
    "        'max_depth': (0, 50),\n",
    "        'min_child_samples': (0, 50),\n",
    "        'max_bin': (100, 1000),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'subsample_freq': (0, 10),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'subsample_for_bin': (100000, 500000),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n",
    "        'n_estimators': (50, 100),\n",
    "    },    \n",
    "    scoring = 'roc_auc',\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 3,\n",
    "    n_iter = ITERATIONS,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")\n",
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "\n",
    "# Fit the model\n",
    "result = bayes_cv_tuner.fit(train_[predictors].values, target.values, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
