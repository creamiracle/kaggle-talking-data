{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split  \n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import operator  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n"
     ]
    }
   ],
   "source": [
    "skip = range(1,181876952)\n",
    "\n",
    "print(\"Loading Data\")\n",
    "train = pd.read_csv('train.csv',skiprows = skip, dtype=dtypes,\n",
    "        header=0,usecols=train_cols,parse_dates=[\"click_time\"])#.sample(1000)\n",
    "test = pd.read_csv('test.csv', dtype=dtypes, header=0,\n",
    "         usecols=test_cols,parse_dates=[\"click_time\"])#.sample(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The initial size of the train set is', 3026939)\n",
      "Binding the training and test set together...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-89bd3bc221b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len_train = len(train)\n",
    "print('The initial size of the train set is', len_train)\n",
    "print('Binding the training and test set together...')\n",
    "train=train.append(test)\n",
    "del test\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21817408, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21817408 entries, 0 to 18790468\n",
      "Data columns (total 6 columns):\n",
      "app              uint16\n",
      "channel          uint16\n",
      "device           uint16\n",
      "ip               uint32\n",
      "is_attributed    float64\n",
      "os               uint16\n",
      "dtypes: float64(1), uint16(4), uint32(1)\n",
      "memory usage: 582.6 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = train.drop(['click_time'], axis = 1)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21817408, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3de001cc2de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The size of the test set is ', 18790469)\n",
      "('The size of the validation set is ', 302694)\n",
      "('The size of the train set is ', 2724245)\n"
     ]
    }
   ],
   "source": [
    "#random split for both \n",
    "train_ = train[:3026939]\n",
    "test = train[3026939:]\n",
    "del train\n",
    "target = 'is_attributed'\n",
    "target = train_[target]\n",
    "train_ = train_.drop(['is_attributed'],axis = 1)\n",
    "train_X,val_X, train_y, val_y = train_test_split(train_,target,test_size = 0.1,random_state = 0) \n",
    "train_y = train_y.astype('uint8')\n",
    "val_y = val_y.astype('uint8')\n",
    "print('The size of the test set is ', len(test))\n",
    "print('The size of the validation set is ', len(val_X))\n",
    "print('The size of the train set is ', len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the datasets for training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the datasets for training...\")\n",
    "params = {\n",
    "          'tree_method': \"approx\", \n",
    "          'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc', \n",
    "          'random_state': 99,\n",
    "          'silent': False,\n",
    "          'colsample_bylevel': 0.1,\n",
    "          'colsample_bytree': 1.0,\n",
    "          'gamma': 5.103973694670875e-08,\n",
    "          'learning_rate': 0.140626707498132,\n",
    "          'max_delta_step': 20,\n",
    "          'max_depth': 6,\n",
    "          'min_child_weight': 4,\n",
    "          'n_estimators': 100,\n",
    "          'reg_alpha': 1e-09,\n",
    "          'reg_lambda': 1000.0,\n",
    "          'scale_pos_weight': 499.99999999999994,\n",
    "          'subsample': 1.0\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.969046\tvalid-auc:0.960367\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 30 rounds.\n",
      "[10]\ttrain-auc:0.977365\tvalid-auc:0.96631\n",
      "[20]\ttrain-auc:0.980361\tvalid-auc:0.968944\n",
      "[30]\ttrain-auc:0.983671\tvalid-auc:0.97074\n",
      "[40]\ttrain-auc:0.986019\tvalid-auc:0.972343\n",
      "[50]\ttrain-auc:0.988119\tvalid-auc:0.973009\n",
      "[60]\ttrain-auc:0.9891\tvalid-auc:0.973238\n",
      "[70]\ttrain-auc:0.990185\tvalid-auc:0.973504\n",
      "[80]\ttrain-auc:0.990611\tvalid-auc:0.973406\n",
      "[90]\ttrain-auc:0.991215\tvalid-auc:0.973425\n",
      "Stopping. Best iteration:\n",
      "[66]\ttrain-auc:0.989869\tvalid-auc:0.973649\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, train_y)\n",
    "del train_X, train_y\n",
    "gc.collect()\n",
    "\n",
    "dvalid = xgb.DMatrix(val_X, val_y)\n",
    "del val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "model = xgb.train(params, dtrain, 1000, watchlist, maximize=True, early_stopping_rounds=30, verbose_eval=10)\n",
    "del dtrain\n",
    "del dvalid\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceate_feature_map(features):  \n",
    "    outfile = open('xgb.fmap', 'w')  \n",
    "    i = 0  \n",
    "    for feat in features:  \n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))  \n",
    "        i = i + 1  \n",
    "    outfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saveing feat_importance!\n"
     ]
    }
   ],
   "source": [
    "print(\"saveing feat_importance!\")\n",
    "features = [x for x in train_.columns if x not in ['id','loss']]  \n",
    "ceate_feature_map(features)  \n",
    "  \n",
    "importance = model.get_fscore(fmap='xgb.fmap')  \n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))  \n",
    "  \n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])  \n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()  \n",
    "df.to_csv(\"../feat_importance.csv\", index=False)  \n",
    "\n",
    "plt.figure()  \n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))  \n",
    "plt.title('XGBoost Feature Importance')  \n",
    "plt.xlabel('relative importance')  \n",
    "plt.savefig(\"feat_importance.jpg\",dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('test.csv', dtype='int', usecols=['click_id'])\n",
    "\n",
    "print(\"predicting...\")\n",
    "sub['is_attributed'] = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "sub.to_csv('sub_xgb_delta.csv',index=False)\n",
    "\n",
    "print(\"All done...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
